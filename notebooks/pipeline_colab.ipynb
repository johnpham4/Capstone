{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWdb9Dcl-x8v",
        "outputId": "4110837d-916b-48d2-beab-57408af4bc92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Capstone'...\n",
            "remote: Enumerating objects: 6874, done.\u001b[K\n",
            "remote: Counting objects: 100% (374/374), done.\u001b[K\n",
            "remote: Compressing objects: 100% (315/315), done.\u001b[K\n",
            "remote: Total 6874 (delta 83), reused 332 (delta 56), pack-reused 6500 (from 3)\u001b[K\n",
            "Receiving objects: 100% (6874/6874), 506.97 MiB | 22.76 MiB/s, done.\n",
            "Resolving deltas: 100% (144/144), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/johnpham4/Capstone.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zDUa5cr_SAQ",
        "outputId": "6dbd1652-d554-4eba-8ff7-8fa888736a41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Capstone\n"
          ]
        }
      ],
      "source": [
        "%cd Capstone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQyJsOYr_bTx",
        "outputId": "1c6686bb-a7e4-49d0-f222-6152dd02cf37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.4/68.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: python-doctr 1.0.0 does not provide the extra 'torch'\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m129.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m138.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.3/512.3 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.9/444.9 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.4/288.4 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m128.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.2/978.2 kB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m113.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.6/525.6 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for geouni (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-adk 1.21.0 requires starlette<1.0.0,>=0.49.1, but you have starlette 0.45.3 which is incompatible.\n",
            "rasterio 1.4.4 requires click!=8.2.*,>=4.0, but you have click 8.2.1 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "mcp 1.24.0 requires pyjwt[crypto]>=2.10.1, but you have pyjwt 2.7.0 which is incompatible.\n",
            "sse-starlette 3.0.4 requires starlette>=0.49.1, but you have starlette 0.45.3 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cmRS3x-Evs-",
        "outputId": "12d4a5bb-f9ca-4bf5-dd6f-71379a29da8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/803.3 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.3/803.3 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "zenml 0.91.2 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
            "google-adk 1.21.0 requires starlette<1.0.0,>=0.49.1, but you have starlette 0.45.3 which is incompatible.\n",
            "google-adk 1.21.0 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\n",
            "langgraph-prebuilt 1.0.5 requires langchain-core>=1.0.0, but you have langchain-core 0.1.23 which is incompatible.\n",
            "google-cloud-bigquery 3.38.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "langgraph-checkpoint 3.0.1 requires langchain-core>=0.2.38, but you have langchain-core 0.1.23 which is incompatible.\n",
            "db-dtypes 1.4.4 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "xarray 2025.12.0 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain==0.0.354 langchain-community==0.0.20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-UJCFnL_fAM",
        "outputId": "dbf1faa7-e8f8-41b5-8e1d-f4379e0670e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mThe `zenml connect` command is deprecated and will be removed in a future \u001b[0m\n",
            "\u001b[33mrelease. Please use the `zenml login` command instead. \u001b[0m\n",
            "\u001b[2;37mCalling `zenml login`\u001b[0m\u001b[2;33m...\u001b[0m\n",
            "Please enter the API key for the ZenML server: \n",
            "\u001b[37mInitializing the ZenML global configuration version to 0.91.2\u001b[0m\n",
            "\u001b[2;37mAuthenticating to ZenML server \u001b[0m\n",
            "\u001b[37m'https://victoria-communicable-sometimes.ngrok-free.dev'\u001b[0m\u001b[2;37m using an API key\u001b[0m\u001b[2;33m...\u001b[0m\n",
            "\u001b[37mSetting the global active project to 'default'.\u001b[0m\n",
            "\u001b[33mSetting the global active stack to default.\u001b[0m\n",
            "\u001b[37mUpdated the global store configuration.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!zenml connect \\\n",
        "  --url https://victoria-communicable-sometimes.ngrok-free.dev \\\n",
        "  --api-key ZENKEY_eyJpZCI6ImUxOGYwNjQ1LWRjZmEtNGQwNS04NWNkLTVkZGNjYzlmZDg5NSIsImtleSI6IjQ3YmU1MGQ5NWNiOWU4NmY2YTI5NWYxNGY5ZjM4NmE3M2IzYWIwZTZhYTk4NDA2M2E5MzI3OWUwYTU5YWI4ZTgifQ=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQmjok_HCI0r",
        "outputId": "382fc0d9-0b63-44c6-9f69-c057cb26375c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2;37m-----ZenML Client Status-----\u001b[0m\n",
            "\u001b[2;37mConnected to a remote ZenML server: \u001b[0m\n",
            "\u001b[2;37m`\u001b[0m\u001b]8;id=939402;https://victoria-communicable-sometimes.ngrok-free.dev\u001b\\\u001b[2;4;94mhttps://victoria-communicable-sometimes.ngrok-free.dev\u001b[0m\u001b]8;;\u001b\\\u001b[2;4;94m`\u001b[0m\n",
            "\u001b[2;37m  Dashboard: \u001b[0m\u001b]8;id=361125;https://victoria-communicable-sometimes.ngrok-free.dev\u001b\\\u001b[2;4;94mhttps://victoria-communicable-sometimes.ngrok-free.dev\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;37m  API: \u001b[0m\u001b]8;id=691325;https://victoria-communicable-sometimes.ngrok-free.dev/docs\u001b\\\u001b[2;4;94mhttps://victoria-communicable-sometimes.ngrok-free.dev\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;37m  Server status: \u001b[0m\u001b[37m'available'\u001b[0m\n",
            "\u001b[2;37m  Server authentication: API key\u001b[0m\n",
            "\u001b[2;37m  The active user is: \u001b[0m\u001b[37m'finetune'\u001b[0m\n",
            "\u001b[2;37m  The active project is: \u001b[0m\u001b[37m'default'\u001b[0m\u001b[2;37m \u001b[0m\u001b[1;2;37m(\u001b[0m\u001b[2;37mglobal\u001b[0m\u001b[1;2;37m)\u001b[0m\n",
            "\u001b[2;37m  The active stack is: \u001b[0m\u001b[37m'default'\u001b[0m\u001b[2;37m \u001b[0m\u001b[1;2;37m(\u001b[0m\u001b[2;37mglobal\u001b[0m\u001b[1;2;37m)\u001b[0m\n",
            "\u001b[2;37mUsing configuration from: \u001b[0m\u001b[37m'/root/.config/zenml'\u001b[0m\n",
            "\u001b[2;37mLocal store files are located at: \u001b[0m\u001b[37m'/root/.config/zenml/local_stores'\u001b[0m\n",
            "\n",
            "\u001b[2;37m-----Local ZenML Server Status-----\u001b[0m\n",
            "\u001b[2;37mThe local server has not been started.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!zenml status"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/draw_line_segments.py --samples 200"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzkr1_ux0Qmq",
        "outputId": "00cb11c5-0070-441c-e5a1-e494adf1717f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2025-12-23 07:28:04.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mGenerating 200 line segments to ./data/line_segments\u001b[0m\n",
            "\u001b[32m2025-12-23 07:28:06.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_line_segments\u001b[0m:\u001b[36m111\u001b[0m - \u001b[1mGenerated 50/200 line segments\u001b[0m\n",
            "\u001b[32m2025-12-23 07:28:08.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_line_segments\u001b[0m:\u001b[36m111\u001b[0m - \u001b[1mGenerated 100/200 line segments\u001b[0m\n",
            "\u001b[32m2025-12-23 07:28:11.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_line_segments\u001b[0m:\u001b[36m111\u001b[0m - \u001b[1mGenerated 150/200 line segments\u001b[0m\n",
            "\u001b[32m2025-12-23 07:28:14.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_line_segments\u001b[0m:\u001b[36m111\u001b[0m - \u001b[1mGenerated 200/200 line segments\u001b[0m\n",
            "\u001b[32m2025-12-23 07:28:14.242\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_line_segments\u001b[0m:\u001b[36m117\u001b[0m - \u001b[32m\u001b[1mCompleted 200 line segments\u001b[0m\n",
            "\u001b[32m2025-12-23 07:28:14.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_line_segments\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1mImages: data/line_segments/images\u001b[0m\n",
            "\u001b[32m2025-12-23 07:28:14.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_line_segments\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mDataset: data/line_segments/dataset.json\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m tools.run --run-inference --no-cache"
      ],
      "metadata": {
        "id": "XVAeyOe7s0vV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m tools.run --run-train --no-cache"
      ],
      "metadata": {
        "id": "bijwxRH6gH9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab3f92b-ba3f-4a9d-edda-b331e0f78933"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[37mNumExpr defaulting to 2 threads.\u001b[0m\n",
            "\u001b[37mTensorFlow version 2.19.0 available.\u001b[0m\n",
            "\u001b[37mJAX version 0.7.2 available.\u001b[0m\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766475605.758265    5407 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766475605.811100    5407 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766475606.178085    5407 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766475606.178131    5407 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766475606.178135    5407 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766475606.178139    5407 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[32m2025-12-23 07:40:15.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipelines.training\u001b[0m:\u001b[36mtraining_pipeline\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mStarting training pipeline\u001b[0m\n",
            "\u001b[32m2025-12-23 07:40:15.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipelines.training\u001b[0m:\u001b[36mtraining_pipeline\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mMerging LoRA adapter\u001b[0m\n",
            "\u001b[32m2025-12-23 07:40:15.636\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mpipelines.training\u001b[0m:\u001b[36mtraining_pipeline\u001b[0m:\u001b[36m56\u001b[0m - \u001b[32m\u001b[1mPipeline completed\u001b[0m\n",
            "\u001b[37mInitiating a new run for the pipeline: \u001b[0m\u001b[38;5;105mtraining_pipeline\u001b[37m.\u001b[0m\n",
            "\u001b[37mCaching is disabled by default for \u001b[0m\u001b[38;5;105mtraining_pipeline\u001b[37m.\u001b[0m\n",
            "\u001b[37mUsing user: \u001b[0m\u001b[38;5;105mfinetune\u001b[37m\u001b[0m\n",
            "\u001b[37mUsing stack: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
            "\u001b[37m  orchestrator: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
            "\u001b[37m  artifact_store: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
            "\u001b[37m  deployer: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
            "\u001b[37mDashboard URL for Pipeline Run: \u001b[0m\u001b[34mhttps://victoria-communicable-sometimes.ngrok-free.dev/projects/default/runs/f7b01a0b-d35a-4ab6-b7ad-a582c0a49f10\u001b[37m\u001b[0m\n",
            "\u001b[37mStep \u001b[0m\u001b[38;5;105mload_model_step\u001b[37m has started.\u001b[0m\n",
            "\u001b[32m2025-12-23 07:40:30.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msteps.train.load_model\u001b[0m:\u001b[36mload_model_step\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mLoading model\u001b[0m\n",
            "\u001b[32m2025-12-23 07:40:30.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.applications.training.model_trainer\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mLoading LLM: Qwen/Qwen2.5-3B-Instruct\u001b[0m\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "\u001b[37m[load_model_step] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set \u001b[0m\u001b[38;5;105mmax_memory\u001b[37m in to a higher value to use more memory (at your own risk).\u001b[0m\n",
            "Loading checkpoint shards: 100% 2/2 [00:29<00:00, 14.61s/it]\n",
            "\u001b[32m2025-12-23 07:41:04.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.applications.training.model_trainer\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mLoading VQ-VAE: JO-KU/Geo-MAGVIT\u001b[0m\n",
            "\u001b[32m2025-12-23 07:41:04.875\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mllm_engineering.applications.training.model_trainer\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m60\u001b[0m - \u001b[32m\u001b[1mModel loaded successfully\u001b[0m\n",
            "[load_model_step] trainable params: 3,686,400 || all params: 3,089,625,088 || trainable%: 0.1193\n",
            "\u001b[33m[load_model_step] No materializer is registered for type \u001b[0m\u001b[38;5;105m<class 'llm_engineering.applications.training.model_trainer.ModelTrainer'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[38;5;105m<class 'llm_engineering.applications.training.model_trainer.ModelTrainer'>\u001b[33m according to the instructions at \u001b[0m\u001b[34mhttps://docs.zenml.io/concepts/artifacts/materializers\u001b[33m\u001b[0m\n",
            "\u001b[37mStep \u001b[0m\u001b[38;5;105mload_model_step\u001b[37m has finished in \u001b[0m\u001b[38;5;105m4m21s\u001b[37m.\u001b[0m\n",
            "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_step\u001b[37m has started.\u001b[0m\n",
            "\u001b[32m2025-12-23 07:45:26.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msteps.train.train_model\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mLoading datasets\u001b[0m\n",
            "\u001b[32m2025-12-23 07:45:26.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.applications.training.model_trainer\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mLoading dataset from /content/Capstone/data/line_segments/dataset_cached.json\u001b[0m\n",
            "\u001b[32m2025-12-23 07:45:26.634\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mllm_engineering.applications.training.model_trainer\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m73\u001b[0m - \u001b[32m\u001b[1mLoaded 200 training samples\u001b[0m\n",
            "\u001b[32m2025-12-23 07:45:26.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msteps.train.train_model\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mStarting training\u001b[0m\n",
            "\u001b[32m2025-12-23 07:45:26.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.applications.training.model_trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mStarting training with cached tokens\u001b[0m\n",
            "\u001b[33m[train_step] /content/Capstone/llm_engineering/applications/training/model_trainer.py:106: FutureWarning: \u001b[0m\u001b[38;5;105mtokenizer\u001b[33m is deprecated and will be removed in version 5.0.0 for \u001b[0m\u001b[38;5;105mTrainer.__init__\u001b[33m. Use \u001b[0m\u001b[38;5;105mprocessing_class\u001b[33m instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[0m\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "  0% 0/18 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "\u001b[33m[train_step] /usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "\u001b[0m\n",
            "{'loss': 4.6445, 'grad_norm': 4.118203163146973, 'learning_rate': 8.888888888888889e-05, 'epoch': 1.48}\n",
            "{'train_runtime': 149.9242, 'train_samples_per_second': 4.002, 'train_steps_per_second': 0.12, 'train_loss': 3.833399348788791, 'epoch': 2.64}\n",
            "100% 18/18 [02:29<00:00,  8.33s/it]\n",
            "\u001b[32m2025-12-23 07:47:57.372\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mllm_engineering.applications.training.model_trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m116\u001b[0m - \u001b[32m\u001b[1mTraining completed\u001b[0m\n",
            "\u001b[32m2025-12-23 07:47:57.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msteps.train.train_model\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mSaving model to checkpoints/line_segments/final\u001b[0m\n",
            "\u001b[32m2025-12-23 07:48:01.627\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msteps.train.train_model\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m31\u001b[0m - \u001b[32m\u001b[1mModel saved to checkpoints/line_segments/final\u001b[0m\n",
            "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_step\u001b[37m has finished in \u001b[0m\u001b[38;5;105m3m6s\u001b[37m.\u001b[0m\n",
            "\u001b[37mStep \u001b[0m\u001b[38;5;105mmerge_lora_step\u001b[37m has started.\u001b[0m\n",
            "\u001b[32m2025-12-23 07:48:05.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msteps.train.merge_model\u001b[0m:\u001b[36mmerge_lora_step\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mLoading base model from Qwen/Qwen2.5-3B-Instruct\u001b[0m\n",
            "\u001b[37m[merge_lora_step] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set \u001b[0m\u001b[38;5;105mmax_memory\u001b[37m in to a higher value to use more memory (at your own risk).\u001b[0m\n",
            "Loading checkpoint shards: 100% 2/2 [00:27<00:00, 13.88s/it]\n",
            "\u001b[33m[merge_lora_step] Some parameters are on the meta device because they were offloaded to the cpu.\u001b[0m\n",
            "\u001b[32m2025-12-23 07:48:33.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msteps.train.merge_model\u001b[0m:\u001b[36mmerge_lora_step\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mLoading LoRA adapter from checkpoints/line_segments/final\u001b[0m\n",
            "\u001b[37m[merge_lora_step] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set \u001b[0m\u001b[38;5;105mmax_memory\u001b[37m in to a higher value to use more memory (at your own risk).\u001b[0m\n",
            "\u001b[32m2025-12-23 07:48:35.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msteps.train.merge_model\u001b[0m:\u001b[36mmerge_lora_step\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mMerging LoRA weights into base model\u001b[0m\n",
            "\u001b[32m2025-12-23 07:48:35.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msteps.train.merge_model\u001b[0m:\u001b[36mmerge_lora_step\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mSaving merged model to checkpoints/line_segments/merged\u001b[0m\n",
            "\u001b[33m[merge_lora_step] /usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:2862: UserWarning: Attempting to save a model with offloaded modules. Ensure that unallocated cpu memory exceeds the \u001b[0m\u001b[38;5;105mshard_size\u001b[33m (5GB default)\n",
            "  warnings.warn(\n",
            "\u001b[0m\n",
            "Saving checkpoint shards: 100% 2/2 [07:35<00:00, 227.61s/it]\n",
            "\u001b[32m2025-12-23 07:56:15.008\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msteps.train.merge_model\u001b[0m:\u001b[36mmerge_lora_step\u001b[0m:\u001b[36m40\u001b[0m - \u001b[32m\u001b[1mMerged model saved to checkpoints/line_segments/merged\u001b[0m\n",
            "\u001b[37mStep \u001b[0m\u001b[38;5;105mmerge_lora_step\u001b[37m has finished in \u001b[0m\u001b[38;5;105m8m11s\u001b[37m.\u001b[0m\n",
            "\u001b[37mPipeline run has finished in \u001b[0m\u001b[38;5;105m15m50s\u001b[37m.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m tools.run --run-inference --no-cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_TJ-DdprGfd",
        "outputId": "53d8c1e8-91ce-4d52-ab21-4544ad7dc3d8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[37mNumExpr defaulting to 2 threads.\u001b[0m\n",
            "\u001b[37mTensorFlow version 2.19.0 available.\u001b[0m\n",
            "\u001b[37mJAX version 0.7.2 available.\u001b[0m\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766476728.944238   10173 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766476728.990184   10173 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766476729.340365   10173 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766476729.340406   10173 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766476729.340410   10173 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766476729.340416   10173 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[32m2025-12-23 07:58:59.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mLoading inference config from /content/Capstone/configs/inference.yaml\u001b[0m\n",
            "\u001b[32m2025-12-23 07:58:59.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mStarting inference pipeline\u001b[0m\n",
            "\u001b[32m2025-12-23 07:58:59.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mModel: /content/Capstone/checkpoints/line_segments/merged\u001b[0m\n",
            "\u001b[32m2025-12-23 07:58:59.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mPrompt: Vẽ đoạn thẳng CD có độ dài 8\u001b[0m\n",
            "\u001b[32m2025-12-23 07:58:59.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipelines.inference\u001b[0m:\u001b[36minference_pipeline\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mStarting inference pipeline\u001b[0m\n",
            "\u001b[32m2025-12-23 07:58:59.682\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mpipelines.inference\u001b[0m:\u001b[36minference_pipeline\u001b[0m:\u001b[36m24\u001b[0m - \u001b[32m\u001b[1mInference completed: <zenml.steps.entrypoint_function_utils.StepArtifact object at 0x7d98227db920>\u001b[0m\n",
            "\u001b[37mInitiating a new run for the pipeline: \u001b[0m\u001b[38;5;105minference_pipeline\u001b[37m.\u001b[0m\n",
            "\u001b[37mCaching is disabled by default for \u001b[0m\u001b[38;5;105minference_pipeline\u001b[37m.\u001b[0m\n",
            "\u001b[37mUsing user: \u001b[0m\u001b[38;5;105mfinetune\u001b[37m\u001b[0m\n",
            "\u001b[37mUsing stack: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
            "\u001b[37m  orchestrator: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
            "\u001b[37m  artifact_store: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
            "\u001b[37m  deployer: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
            "\u001b[37mDashboard URL for Pipeline Run: \u001b[0m\u001b[34mhttps://victoria-communicable-sometimes.ngrok-free.dev/projects/default/runs/02b64b8c-2387-41d1-a9dc-d6eb744b8b84\u001b[37m\u001b[0m\n",
            "\u001b[37mStep \u001b[0m\u001b[38;5;105mtest_inference_step\u001b[37m has started.\u001b[0m\n",
            "\u001b[32m2025-12-23 07:59:13.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msteps.inference.test_inference\u001b[0m:\u001b[36mtest_inference_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mLoading models for inference test\u001b[0m\n",
            "\u001b[32m2025-12-23 07:59:13.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msteps.inference.test_inference\u001b[0m:\u001b[36mtest_inference_step\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mLoading model from: /content/Capstone/checkpoints/line_segments/merged\u001b[0m\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "\u001b[37m[test_inference_step] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set \u001b[0m\u001b[38;5;105mmax_memory\u001b[37m in to a higher value to use more memory (at your own risk).\u001b[0m\n",
            "Loading checkpoint shards: 100% 2/2 [00:27<00:00, 13.81s/it]\n",
            "config.json: 100% 67.0/67.0 [00:00<00:00, 1.70kB/s]\n",
            "pytorch_model.safetensors: 100% 696M/696M [00:15<00:00, 44.6MB/s]\n",
            "\u001b[32m2025-12-23 07:59:59.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msteps.inference.test_inference\u001b[0m:\u001b[36mtest_inference_step\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1mTest prompt: Vẽ đoạn thẳng CD có độ dài 8\u001b[0m\n",
            "\u001b[32m2025-12-23 07:59:59.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msteps.inference.test_inference\u001b[0m:\u001b[36mtest_inference_step\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mGenerating image tokens\u001b[0m\n",
            "\u001b[32m2025-12-23 08:00:55.737\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msteps.inference.test_inference\u001b[0m:\u001b[36mtest_inference_step\u001b[0m:\u001b[36m98\u001b[0m - \u001b[33m\u001b[1mCould not extract image tokens with markers: 151667 is not in list\u001b[0m\n",
            "\u001b[32m2025-12-23 08:00:55.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msteps.inference.test_inference\u001b[0m:\u001b[36mtest_inference_step\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mUsing fallback: first 1024 generated tokens\u001b[0m\n",
            "\u001b[32m2025-12-23 08:00:55.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msteps.inference.test_inference\u001b[0m:\u001b[36mtest_inference_step\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mDecoding tokens to image, shape: torch.Size([1, 1024])\u001b[0m\n",
            "\u001b[32m2025-12-23 08:00:58.323\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msteps.inference.test_inference\u001b[0m:\u001b[36mtest_inference_step\u001b[0m:\u001b[36m121\u001b[0m - \u001b[32m\u001b[1mTest image generated: /content/Capstone/outputs/inference_test/test_generated.png\u001b[0m\n",
            "\u001b[37mStep \u001b[0m\u001b[38;5;105mtest_inference_step\u001b[37m has finished in \u001b[0m\u001b[38;5;105m1m47s\u001b[37m.\u001b[0m\n",
            "\u001b[37mPipeline run has finished in \u001b[0m\u001b[38;5;105m1m50s\u001b[37m.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reset"
      ],
      "metadata": {
        "id": "ccTEfkkM81Fg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "kwYOVxmfERs8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "871a882f-561e-4b7b-c16d-3b4bdec48118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf Capstone"
      ],
      "metadata": {
        "id": "g8ZVsAKe83BP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA6JgUri84-B",
        "outputId": "81afe771-b517-4038-b9f7-56278c71e737"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0k6InMQiCG7A"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}